{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpecMetrics - Processing from AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = os.environ['HOME'] + '/Dev/spec_metrics_dashboard'\n",
    "sys.path.append(ROOT_DIR + '/src/lib')\n",
    "\n",
    "import connector_s3, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_keys = process.fetch_run_keys(connector_s3)\n",
    "runs_df = process.build_runs_df(run_keys)\n",
    "runs_df.index = runs_df.date\n",
    "\n",
    "branch_names = process.branch_names(runs_df=runs_df)\n",
    "print(len(branch_names), \"branches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_key = \"raw/jobteaser-jobteaser/20160928181433126-develop-79b5bf12\"\n",
    "run_data = process.fetch_run_data(connector_s3, run_key)\n",
    "examples_df = process.build_run_examples_df(run_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "level_0_paths = sorted(set(examples_df.path_0))\n",
    "for level_0_path in level_0_paths:\n",
    "    level_1_paths = examples_df[examples_df.path_0 == level_0_path].path_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examples_df.groupby([\"path_0\", \"path_1\", \"path_2\", \"path_3\", \"path_4\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying recurring failing examples solved by rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of unique failed examples: \n",
    "- 56 over last 50 runs\n",
    "- 75 over last 100 runs\n",
    "- 147 over last 200 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_failed_examples_df = pd.DataFrame()\n",
    "develop_run_keys = list(runs_df[runs_df.branch == \"develop\"].run_key)\n",
    "for key in tqdm(list(reversed(develop_run_keys))[0:200]):\n",
    "    data = process.fetch_run_data(connector_s3, key)\n",
    "    examples_df = process.build_run_examples_df(data)\n",
    "    if len(examples_df) == 0:\n",
    "        # we may have runs with no examples, in this case the df is empty\n",
    "        continue\n",
    "    failed_examples_df = examples_df[examples_df.status == \"failed\"]\n",
    "    all_failed_examples_df = all_failed_examples_df.append(failed_examples_df, ignore_index=True)\n",
    "\n",
    "print(\"Count of found unique failed examples over N last develop runs:\", len(all_failed_examples_df.drop_duplicates(\"description\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "most_failed_example_description = all_failed_examples_df.groupby(\"description\") \\\n",
    "    .count().sort_values(by=\"path_0\", ascending=False).index[0]\n",
    "most_failed_example_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_failed_examples_df.groupby(\"description\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to find the examples that were run before the most failed example ran. Must isolate them in the case the most failed example failed. We may also isolate the tests that run before when it didn't fail, to have white and blacklists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all examples that failed before the most failed example,\n",
    "# add them to \"all_before_most_failed_examples_df\" and get\n",
    "# insights from this.\n",
    "#\n",
    "# NB: this is the union, not the intersection!\n",
    "\n",
    "LIMIT = 50\n",
    "all_before_most_failed_examples_df = pd.DataFrame()\n",
    "count_of_runs_with_most_failed_example_failed = 0\n",
    "\n",
    "develop_run_keys = list(runs_df[runs_df.branch == \"develop\"].run_key)\n",
    "for key in tqdm(list(reversed(develop_run_keys))[0:LIMIT]):\n",
    "    data = process.fetch_run_data(connector_s3, key)\n",
    "    examples_df = process.build_run_examples_df(data)\n",
    "\n",
    "    if len(examples_df) == 0:\n",
    "        # no examples in this run\n",
    "        continue\n",
    "    \n",
    "    most_failed_example = examples_df[examples_df.description == most_failed_example_description]\n",
    "    if len(most_failed_example) == 0:\n",
    "        # most failed example not present in this run\n",
    "        continue\n",
    "    \n",
    "    if most_failed_example.status.iloc[0] == \"passed\":\n",
    "        # the most failed example did not fail in this run, ignoring it\n",
    "        continue\n",
    "        \n",
    "    count_of_runs_with_most_failed_example_failed += 1\n",
    "\n",
    "    examples_df.index = examples_df.finished_at\n",
    "    most_failed_example_finished_at = most_failed_example.finished_at.iloc[0]\n",
    "    before_most_failed_examples_df = examples_df[examples_df.finished_at < most_failed_example_finished_at]\n",
    "    \n",
    "    all_before_most_failed_examples_df = all_before_most_failed_examples_df.append(\n",
    "        before_most_failed_examples_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "failure_source_examples_df = all_before_most_failed_examples_df[[\"description\", \"path_0\"]].groupby(\"description\").count()\n",
    "failure_source_examples_df.columns = [\"count\"]\n",
    "failure_source_examples_df[\"presence\"] = failure_source_examples_df[\"count\"] / count_of_runs_with_most_failed_example_failed\n",
    "failure_source_examples_df[failure_source_examples_df.presence > 0.9].sort_values(by=\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection of examples present before a given failing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all examples that failed before the most failed example,\n",
    "# build the intersection of their descriptions and get insights\n",
    "# from this.\n",
    "#\n",
    "# NB: this is the intersection!\n",
    "#\n",
    "# TODO: use pandas dataframe intersection instead!\n",
    "\n",
    "LIMIT = 50\n",
    "before_most_failed_example_descriptions_intersection = []\n",
    "\n",
    "develop_run_keys = list(runs_df[runs_df.branch == \"develop\"].run_key)\n",
    "for key in tqdm(list(reversed(develop_run_keys))[0:LIMIT]):\n",
    "    data = process.fetch_run_data(connector_s3, key)\n",
    "    examples_df = process.build_run_examples_df(data)\n",
    "\n",
    "    if len(examples_df) == 0:\n",
    "        # no examples in this run\n",
    "        continue\n",
    "    \n",
    "    most_failed_example = examples_df[examples_df.description == most_failed_example_description]\n",
    "    if len(most_failed_example) == 0:\n",
    "        # most failed example not present in this run\n",
    "        continue\n",
    "    \n",
    "    if most_failed_example.status.iloc[0] == \"passed\":\n",
    "        # the most failed example did not fail in this run, ignoring it\n",
    "        continue\n",
    "        \n",
    "    examples_df.index = examples_df.finished_at\n",
    "    most_failed_example_finished_at = most_failed_example.finished_at.iloc[0]\n",
    "    before_most_failed_examples_df = examples_df[examples_df.finished_at < most_failed_example_finished_at]\n",
    "    before_most_failed_example_descriptions = list(set(before_most_failed_examples_df.description))\n",
    "\n",
    "    if len(before_most_failed_example_descriptions_intersection) == 0:\n",
    "        # empty, add first descriptions before intersecting\n",
    "        before_most_failed_example_descriptions_intersection += before_most_failed_example_descriptions\n",
    "    else:\n",
    "        # intersecting\n",
    "        before_most_failed_example_descriptions_intersection = list(\n",
    "            set(before_most_failed_example_descriptions_intersection) & \\\n",
    "            set(before_most_failed_example_descriptions)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = process.fetch_run_data(connector_s3, develop_run_keys[-2])\n",
    "examples_df = process.build_run_examples_df(data)\n",
    "examples_df[examples_df.description == 'StudentNews#send_news_notifications should have a job queued with [\"StudentMailer\", \"news_recap\", \"student_profile_id\"]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import highcharts\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%run setup_highcharts.py\n",
    "load_highcharts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_highcharts_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "branch_runs_df = runs_df[runs_df.branch == \"develop\"]\n",
    "run_key = branch_runs_df.to_dict(orient=\"rows\")[-22][\"run_key\"]\n",
    "run_data = process.fetch_run_data(connector_s3, run_key)\n",
    "run_examples_df = process.build_run_examples_df(run_data)\n",
    "\n",
    "chart_df = run_examples_df[[\"path_0\", \"path_1\", \"run_time\"]] \\\n",
    "    .groupby(['path_0', 'path_1']) \\\n",
    "    .sum()[['run_time']]\n",
    "    \n",
    "chart_js = highcharts.pie_drilldown(\n",
    "    chart_df,\n",
    "    serie_name='Run time',\n",
    "    title=\"Run time\",\n",
    "    percentage=False,\n",
    "    unit=\"s\"\n",
    ")\n",
    "\n",
    "display(HTML(\"<div id='chart'><script>\" + chart_js +\"</script>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
